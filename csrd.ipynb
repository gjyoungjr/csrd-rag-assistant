{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSRD RAG Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.11/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.11/site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.11/site-packages (3.1)\n",
      "Requirement already satisfied: pyvis in /opt/anaconda3/lib/python3.11/site-packages (0.3.2)\n",
      "Requirement already satisfied: langchain in /opt/anaconda3/lib/python3.11/site-packages (0.2.5)\n",
      "Requirement already satisfied: langchain_openai in /opt/anaconda3/lib/python3.11/site-packages (0.1.8)\n",
      "Requirement already satisfied: faiss-cpu in /opt/anaconda3/lib/python3.11/site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: duckduckgo-search in /opt/anaconda3/lib/python3.11/site-packages (7.2.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests) (2024.6.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.5)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from pyvis) (8.20.0)\n",
      "Requirement already satisfied: jinja2>=2.9.6 in /opt/anaconda3/lib/python3.11/site-packages (from pyvis) (3.1.3)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /opt/anaconda3/lib/python3.11/site-packages (from pyvis) (4.0.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.0.25)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.2.9)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.2.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (0.1.80)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain) (8.3.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_openai) (1.50.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in /opt/anaconda3/lib/python3.11/site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.11/site-packages (from faiss-cpu) (23.2)\n",
      "Requirement already satisfied: click>=8.1.7 in /opt/anaconda3/lib/python3.11/site-packages (from duckduckgo-search) (8.1.7)\n",
      "Requirement already satisfied: primp>=0.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from duckduckgo-search) (0.10.1)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from duckduckgo-search) (5.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/anaconda3/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.18.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5 in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (5.7.1)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.11/site-packages (from ipython>=5.3.0->pyvis) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2>=2.9.6->pyvis) (2.1.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.7->langchain) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.26.0->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/anaconda3/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.23.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.10.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/anaconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis) (0.8.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.7->langchain) (2.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.11/site-packages (from stack-data->ipython>=5.3.0->pyvis) (0.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4 pandas networkx pyvis langchain langchain_openai faiss-cpu duckduckgo-search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from bs4.element import Tag\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from pyvis.network import Network\n",
    "import uuid\n",
    "import networkx as nx\n",
    "import faiss\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema.retriever import BaseRetriever\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.callbacks.manager import CallbackManagerForRetrieverRun\n",
    "from typing import List, Any  \n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csrd_report_url = 'https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:02013L0034-20240109&qid=1712714544806'\n",
    "html_page = requests.get(csrd_report_url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_directive_section(main_content):\n",
    "  return main_content.find('div', {'class': 'eli-main-title'})\n",
    "\n",
    "def get_content_section(main_content):\n",
    "  return main_content.find('div', {'class': 'eli-subdivision'})\n",
    "\n",
    "def get_chapter_sections(content_section):\n",
    "  return content_section.find_all('div', recursive=False)\n",
    "\n",
    "def get_article_sections(chapter_section):\n",
    "  return chapter_section.find_all('div', {'class': 'eli-subdivision'}, recursive=False)\n",
    "\n",
    "def get_directive_name(directive_section) -> str:\n",
    "  title_doc = directive_section.find_all('p', {'class': 'title-doc-first'})\n",
    "  title_doc = ' '.join([t.text.strip() for t in title_doc])\n",
    "  return title_doc\n",
    "\n",
    "def get_chapter_name(chapter_section) -> str:\n",
    "  return chapter_section.find('p', {'class': 'title-division-2'}).text.strip().capitalize()\n",
    "\n",
    "def get_chapter_id(chapter_section) -> str:\n",
    "  chapter_id = chapter_section.find('p', {'class': 'title-division-1'}).text.strip()\n",
    "  chapter_id = chapter_id.replace('CHAPTER', '').strip()\n",
    "  return chapter_id\n",
    "\n",
    "def get_article_name(article_section) -> str:\n",
    "  return article_section.find('p', {'class': 'stitle-article-norm'}).text.strip()\n",
    "\n",
    "def get_article_id(article_section) -> str:\n",
    "  article_id = article_section.find('p', {'class': 'title-article-norm'}).text.strip()\n",
    "  article_id = re.sub('\\\"?Article\\s*', '', article_id).strip()\n",
    "  return article_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _clean_paragraph(txt):\n",
    "  # remove multiple break lines\n",
    "  txt = re.sub('\\n+', '\\n', txt)\n",
    "  # simplifies bullet points\n",
    "  txt = re.sub('(\\([\\d\\w]+\\)\\s?)\\n', r'\\1\\t', txt)\n",
    "  # simplifies quote\n",
    "  txt = re.sub('‘', '\\'', txt)\n",
    "  # some weird references to other articles\n",
    "  txt = re.sub('\\(\\\\n[\\d\\w]+\\n\\)', '', txt)\n",
    "  # remove spaces before punctuation\n",
    "  txt = re.sub(f'\\s([\\.;:])', r'\\1', txt)\n",
    "  # remove reference links\n",
    "  txt = re.sub('▼\\w+\\n', '', txt)\n",
    "  # format numbers\n",
    "  txt = re.sub('(?<=\\d)\\s(?=\\d)', '', txt)\n",
    "  # remove consecutive spaces\n",
    "  txt = re.sub('\\s{2,}', ' ', txt)\n",
    "  # remove leading / trailing spaces\n",
    "  txt = txt.strip()\n",
    "  return txt \n",
    "\n",
    "def get_paragraphs(article_section):\n",
    "  content = {}\n",
    "  paragraph_number = '0'\n",
    "  paragraph_content = []\n",
    "  for child in article_section.children:\n",
    "    if isinstance(child, Tag):\n",
    "      if 'norm' in child.attrs.get('class'):\n",
    "        if child.name == 'p':\n",
    "          paragraph_content.append(child.text.strip())\n",
    "        elif child.name == 'div':\n",
    "          content[paragraph_number] = _clean_paragraph('\\n'.join(paragraph_content))\n",
    "          paragraph_number = child.find('span', {'class': 'no-parag'}).text.strip().split('.')[0]\n",
    "          paragraph_content = [child.find('div', {'class': 'inline-element'}).text]\n",
    "      elif 'grid-container' in child.attrs.get('class'):\n",
    "        paragraph_content.append(child.text)\n",
    "    content[paragraph_number] = _clean_paragraph('\\n'.join(paragraph_content))\n",
    "  return {k:v for k, v in content.items() if len(v) > 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chapter 1: Scope, definitions and categories of undertakings and groups\n",
      "3 article(s)\n",
      "\n",
      "Chapter 2: General provisions and principles\n",
      "5 article(s)\n",
      "\n",
      "Chapter 3: Balance sheet and profit and loss account\n",
      "6 article(s)\n",
      "\n",
      "Chapter 4: Notes to the financial statements\n",
      "4 article(s)\n",
      "\n",
      "Chapter 5: Management report\n",
      "3 article(s)\n",
      "\n",
      "Chapter 6: Consolidated financial statements and reports\n",
      "10 article(s)\n",
      "\n",
      "Chapter 6a: Sustainability reporting standards\n",
      "2 article(s)\n",
      "\n",
      "Chapter 6b: Single electronic reporting format\n",
      "1 article(s)\n",
      "\n",
      "Chapter 7: Publication\n",
      "5 article(s)\n",
      "\n",
      "Chapter 8: Auditing and assurance of sustainability reporting\n",
      "2 article(s)\n",
      "\n",
      "Chapter 9: Provisions concerning exemptions and restrictions on exemptions\n",
      "5 article(s)\n",
      "\n",
      "Chapter 9a: Reporting concerning third-country undertakings\n",
      "4 article(s)\n",
      "\n",
      "Chapter 10: Report on payments to governments\n",
      "8 article(s)\n",
      "\n",
      "Chapter 10a: Report on income tax information\n",
      "8 article(s)\n",
      "\n",
      "Chapter 11: Transitional and final provisions\n",
      "8 article(s)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main_content = BeautifulSoup(html_page, 'html.parser')\n",
    "directive_section = get_directive_section(main_content)\n",
    "directive_name = get_directive_name(directive_section)\n",
    "content_section = get_content_section(main_content)\n",
    "\n",
    "for chapter_section in get_chapter_sections(content_section):\n",
    "  chapter_id = get_chapter_id(chapter_section)\n",
    "  chapter_name = get_chapter_name(chapter_section)\n",
    "  articles = len(get_article_sections(chapter_section))\n",
    "  print(f'Chapter {chapter_id}: {chapter_name}')\n",
    "  print(f'{articles} article(s)')\n",
    "  print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "edges = []\n",
    "\n",
    "nodes.append(['0', 'CSRD', directive_name, 'DIRECTIVE'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for chapter_section in get_chapter_sections(content_section):\n",
    "\n",
    "  chapter_id = get_chapter_id(chapter_section)\n",
    "  chapter_name = get_chapter_name(chapter_section)\n",
    "\n",
    "  # level 1, chapter\n",
    "  # chapters are included in root node\n",
    "  nodes.append([ chapter_id, f'Chapter {chapter_id}', chapter_name, 'CHAPTER'])\n",
    "  edges.append(['0', f'{chapter_id}', 'CONTAINS'])\n",
    "\n",
    "  for article_section in get_article_sections(chapter_section):\n",
    "    article_id = get_article_id(article_section)\n",
    "    article_name = get_article_name(article_section)\n",
    "    article_paragraphs = get_paragraphs(article_section)\n",
    "\n",
    "    # level 2, article\n",
    "    # articles are included in chapters\n",
    "    nodes.append([f'{chapter_id}.{article_id}', f'Article {article_id}', article_name, 'ARTICLE'])\n",
    "    edges.append([chapter_id, f'{chapter_id}.{article_id}', 'CONTAINS'])\n",
    "\n",
    "    for paragraph_id, paragraph_text in article_paragraphs.items():\n",
    "\n",
    "      # level 3, paragraph\n",
    "      # paragraphs are included in articles\n",
    "      nodes.append([f'{chapter_id}.{article_id}.{paragraph_id}', f'Article {article_id}({paragraph_id})', paragraph_text, 'PARAGRAPH'])\n",
    "      edges.append([f'{chapter_id}.{article_id}', f'{chapter_id}.{article_id}.{paragraph_id}', 'CONTAINS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_df = pd.DataFrame(nodes, columns=['id', 'label', 'content', 'group'])\n",
    "edges_df = pd.DataFrame(edges, columns=['src', 'dst', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CONTAINS'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display(edges_df)\n",
    "edges_df['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CSRD</td>\n",
       "      <td>DIRECTIVE 2013/34/EU OF THE EUROPEAN PARLIAMEN...</td>\n",
       "      <td>DIRECTIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Chapter 1</td>\n",
       "      <td>Scope, definitions and categories of undertaki...</td>\n",
       "      <td>CHAPTER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1</td>\n",
       "      <td>Article 1</td>\n",
       "      <td>Scope</td>\n",
       "      <td>ARTICLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1.1</td>\n",
       "      <td>Article 1(1)</td>\n",
       "      <td>The coordination measures prescribed by this D...</td>\n",
       "      <td>PARAGRAPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1.1a</td>\n",
       "      <td>Article 1(1a)</td>\n",
       "      <td>The coordination measures prescribed by Articl...</td>\n",
       "      <td>PARAGRAPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>11.53.2</td>\n",
       "      <td>Article 53(2)</td>\n",
       "      <td>Member States shall communicate to the Commiss...</td>\n",
       "      <td>PARAGRAPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>11.54</td>\n",
       "      <td>Article 54</td>\n",
       "      <td>Entry into force</td>\n",
       "      <td>ARTICLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>11.54.0</td>\n",
       "      <td>Article 54(0)</td>\n",
       "      <td>This Directive shall enter into force on the t...</td>\n",
       "      <td>PARAGRAPH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>11.55</td>\n",
       "      <td>Article 55</td>\n",
       "      <td>Addressees</td>\n",
       "      <td>ARTICLE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>11.55.0</td>\n",
       "      <td>Article 55(0)</td>\n",
       "      <td>This Directive is addressed to the Member States.</td>\n",
       "      <td>PARAGRAPH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>375 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          label  \\\n",
       "0          0           CSRD   \n",
       "1          1      Chapter 1   \n",
       "2        1.1      Article 1   \n",
       "3      1.1.1   Article 1(1)   \n",
       "4     1.1.1a  Article 1(1a)   \n",
       "..       ...            ...   \n",
       "370  11.53.2  Article 53(2)   \n",
       "371    11.54     Article 54   \n",
       "372  11.54.0  Article 54(0)   \n",
       "373    11.55     Article 55   \n",
       "374  11.55.0  Article 55(0)   \n",
       "\n",
       "                                               content      group  \n",
       "0    DIRECTIVE 2013/34/EU OF THE EUROPEAN PARLIAMEN...  DIRECTIVE  \n",
       "1    Scope, definitions and categories of undertaki...    CHAPTER  \n",
       "2                                                Scope    ARTICLE  \n",
       "3    The coordination measures prescribed by this D...  PARAGRAPH  \n",
       "4    The coordination measures prescribed by Articl...  PARAGRAPH  \n",
       "..                                                 ...        ...  \n",
       "370  Member States shall communicate to the Commiss...  PARAGRAPH  \n",
       "371                                   Entry into force    ARTICLE  \n",
       "372  This Directive shall enter into force on the t...  PARAGRAPH  \n",
       "373                                         Addressees    ARTICLE  \n",
       "374  This Directive is addressed to the Member States.  PARAGRAPH  \n",
       "\n",
       "[375 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(nodes_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "csrd_graph = nx.DiGraph()\n",
    "\n",
    "for i, n in nodes_df.iterrows():\n",
    "  csrd_graph.add_node(n['id'], label=n['label'], title=n['content'], group=n['group'])\n",
    "\n",
    "for i, e in edges_df.iterrows():\n",
    "  if e['label'] == 'CONTAINS':\n",
    "    csrd_graph.add_edge(e['src'], e['dst'], label=e['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def displayGraph(graph):\n",
    "\n",
    "#   net = Network(\n",
    "#     height=\"750px\", \n",
    "#     width=\"100%\", \n",
    "#     directed=True, \n",
    "#     cdn_resources='remote',\n",
    "#     notebook=True\n",
    "#   )\n",
    "\n",
    "#   net.options.groups = {\n",
    "#       \"DIRECTIVE\": {\n",
    "#         \"icon\": {\n",
    "#             \"face\": 'FontAwesome',\n",
    "#             \"code\": '\\uf19c',\n",
    "#         }\n",
    "#       },\n",
    "#       \"CHAPTER\": {\n",
    "#           \"icon\": {\n",
    "#               \"face\": 'FontAwesome',\n",
    "#               \"code\": '\\uf02d',\n",
    "#           }\n",
    "#       },\n",
    "#       \"ARTICLE\": {                 \n",
    "#         \"icon\": {\n",
    "#             \"face\": 'FontAwesome',\n",
    "#             \"code\": '\\uf07c',\n",
    "#           }\n",
    "#       },\n",
    "#       \"PARAGRAPH\": {                 \n",
    "#         \"icon\": {\n",
    "#             \"face\": 'FontAwesome',\n",
    "#             \"code\": '\\uf15b',\n",
    "#           }\n",
    "#       }\n",
    "#   }\n",
    "\n",
    "#   net.from_nx(graph)\n",
    "#   net.show(f\"/tmp/{uuid.uuid4().hex}.html\")\n",
    "#   return net.html.replace(\n",
    "#     '<head>',\n",
    "#     '<head><link rel=\"stylesheet\" href=\"https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css\" type=\"text/css\"/>'\n",
    "#   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Create a guided checklist of standards i should follow while reporting my emissions.\n",
      "\n",
      "Answer: To ensure compliance with the CSRD directive when reporting emissions, follow these standards:\n",
      "- Specify scope 1, scope 2, and where relevant, scope 3 greenhouse gas emissions (Article 19a(2)(a)(i))\n",
      "- Include information on climate change mitigation and adaptation (Article 19a(2)(a)(ii))\n",
      "- Disclose information on water and marine resources, resource use, circular economy, pollution, biodiversity, and ecosystems (Article 19a(2)(a)(iii)-(vi))\n",
      "\n",
      "Sources:\n",
      "- Article 29b(1): The Commission shall adopt delegated acts in accordance with Article 49 supplementing this Directive...\n",
      "- Article 29b(2): The sustainability reporting standards shall ensure the quality of reported information, by requirin...\n",
      "- Article 29b(3): The sustainability reporting standards shall specify the forward-looking, retrospective, qualitative...\n",
      "- Article 29b(4): Sustainability reporting standards shall take account of the difficulties that undertakings may enco...\n",
      "- Article 29b(5): When adopting delegated acts pursuant to paragraph 1, the Commission shall, to the greatest extent p...\n",
      "- Article 29c(1): The Commission shall, by 30 June 2024, adopt delegated acts in accordance with Article 49 supplement...\n",
      "- Article 29c(2): Sustainability reporting standards for small and medium-sized undertakings shall take into account t...\n",
      "- Article 29c(3): The Commission shall, at least every three years after their date of application, review the delegat...\n"
     ]
    }
   ],
   "source": [
    "from networkx import DiGraph  # Added this import\n",
    "\n",
    "\n",
    "# Initialize embeddings and LLM\n",
    "embeddings = OpenAIEmbeddings()\n",
    "chat_model = ChatOpenAI(temperature=0)\n",
    "\n",
    "# Create vector store\n",
    "def create_vector_store(nodes_df):\n",
    "    texts = nodes_df['content'].tolist()\n",
    "    metadatas = [{'id': id} for id in nodes_df['id'].tolist()]\n",
    "    return FAISS.from_texts(texts, embeddings, metadatas=metadatas)\n",
    "\n",
    "vector_store = create_vector_store(nodes_df)\n",
    "CSRD_search = vector_store.as_retriever()\n",
    "\n",
    "\n",
    "# Custom Retriever\n",
    "class CustomRetriever(BaseRetriever):\n",
    "    retriever: Any\n",
    "    knowledge_graph: DiGraph\n",
    "\n",
    "    def _get_relevant_documents(self, query: str, *, run_manager: CallbackManagerForRetrieverRun) -> List[Document]:\n",
    "        # Use existing retriever to get the documents\n",
    "        documents = self.retriever.get_relevant_documents(query)\n",
    "\n",
    "        # Retrieve document Ids\n",
    "        doc_ids = [doc.metadata['id'] for doc in documents]\n",
    "\n",
    "        # Retrieve nodes\n",
    "        nodes = [[node_id, self.knowledge_graph.nodes.get(node_id)] for node_id in doc_ids]\n",
    "        nodes = [[node_id, node_data] for node_id, node_data in nodes if node_data is not None]\n",
    "\n",
    "        # Build documents in relevance order\n",
    "        processed_ids = set()\n",
    "        supporting_documents = []\n",
    "\n",
    "        for node_id, node_data in nodes:\n",
    "            if node_data['group'] == 'PARAGRAPH' and node_id not in processed_ids:\n",
    "                processed_ids.add(node_id)\n",
    "                supporting_documents.append(\n",
    "                    Document(\n",
    "                        page_content=node_data['title'],\n",
    "                        metadata={'id': node_id, 'label': node_data['label']}\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            # Traverse graph to get cross reference articles\n",
    "            children_id = list(self.knowledge_graph.successors(node_id))\n",
    "            for child_id in children_id:\n",
    "                child_data = self.knowledge_graph.nodes[child_id]\n",
    "                if child_data['group'] == 'PARAGRAPH' and child_id not in processed_ids:\n",
    "                    processed_ids.add(child_id)\n",
    "                    supporting_documents.append(\n",
    "                        Document(\n",
    "                            page_content=child_data['title'],\n",
    "                            metadata={'id': child_id, 'label': child_data['label']}\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "        return supporting_documents\n",
    "\n",
    "# Setup prompt and chain\n",
    "TEMPLATE = \"\"\"\n",
    "Context information is below.\n",
    "\n",
    "---------------------\n",
    "{context}\n",
    "---------------------\n",
    "\n",
    "Given the context information and not prior knowledge.\n",
    "Answer compliance issue related to the CSRD directive only.\n",
    "\n",
    "If the question is not related to regulatory compliance, kindly decline to answer.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Keep the answer as concise as possible, citing articles and chapters whenever applicable.\n",
    "Please do not repeat the answer and do not add any additional information.\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=TEMPLATE, input_variables=[\"context\", \"question\"])\n",
    "\n",
    "# Create chain\n",
    "chain_kg = RetrievalQA.from_chain_type(\n",
    "    llm=chat_model,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=CustomRetriever(retriever=CSRD_search, knowledge_graph=csrd_graph),\n",
    "    chain_type_kwargs={\"prompt\": prompt},\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "def format_response(question, answer):\n",
    "    print(f\"Question: {question}\\n\")\n",
    "    print(f\"Answer: {answer['result']}\\n\")\n",
    "    print(\"Sources:\")\n",
    "    for doc in answer['source_documents']:\n",
    "        print(f\"- {doc.metadata['label']}: {doc.page_content[:100]}...\")\n",
    "\n",
    "question = \"Create a guided checklist of standards i should follow while reporting my emissions.\"\n",
    "answer = chain_kg.invoke({\"query\": question})\n",
    "format_response(question, answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic Approach of CSRD Agent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "\n",
    "from langchain import OpenAI, LLMChain\n",
    "from langchain.tools import DuckDuckGoSearchRun\n",
    "\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re\n",
    "import langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = []\n",
    "metadata = []\n",
    "\n",
    "for node_id, node_data in csrd_graph.nodes(data=True):\n",
    "  text.append(node_data['title'])\n",
    "  metadata.append({'id': node_id, 'label': node_data['label']})\n",
    "  \n",
    "embeddings = OpenAIEmbeddings()\n",
    "csrd_vector_store = FAISS.from_texts(text, embeddings, metadatas=metadata)\n",
    "\n",
    "\n",
    "def search_csrd(query: str) -> str:\n",
    "  csrd_results = csrd_vector_store.similarity_search_with_score(query)\n",
    "  print(csrd_results)\n",
    "  \n",
    "  response = []\n",
    "  \n",
    "  for doc, score in csrd_results:\n",
    "    doc_id = doc.metadata['id']\n",
    "    doc_label = doc.metadata['label']\n",
    "    doc_content = doc.page_content\n",
    "    doc_references = ','.join(list(csrd_graph.neighbors(doc_id)))\n",
    "    \n",
    "    response.append(\n",
    "      f'''######\n",
    "      [Articel ID]: {doc_id}\n",
    "      [Article Name]: {doc_label}\n",
    "      [Article Content]: {doc_content}\n",
    "      [References]: {doc_references}\n",
    "      '''\n",
    "    )\n",
    "    \n",
    "    return \"\\n\\n\".join(response)\n",
    "    \n",
    "def search_reference(article_reference: str) -> str: \n",
    "  result = csrd_graph.nodes[article_reference]\n",
    "  doc_references = ','.join(list(csrd_graph.neighbors(article_reference)))\n",
    "  doc_content = result['title']\n",
    "  doc_label = result['label']\n",
    "  \n",
    "  return f'''###\n",
    "  [Articel ID]: {article_reference}\n",
    "  [Article Name]: {doc_label}\n",
    "  [Article Content]: {doc_content}\n",
    "  [References]: {doc_references}\n",
    "'''\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which tools the agent can use to answer user queries\n",
    "search = DuckDuckGoSearchRun()\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"search_csrd\",\n",
    "        func=search_csrd,\n",
    "        description=\"useful for when you need to answer questions about CSRD directive\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name = \"expand_search_reference\",\n",
    "        func=search_reference,\n",
    "        description=\"useful for when you need to answer questions about CSRD directive\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "You are an expert in sustainability reporting compliance. \n",
    "Given the context information, answer compliance issues related to the CSRD directive.\n",
    "Start your search with content related to a given query using the [search_csrd] tool.\n",
    "Each article may have [article_references] to other articles. Expand your search using the [expand_search_reference] tool.\n",
    "Continue your search until all referenced information have been used to answer the question.\n",
    "\n",
    "If the question is not related to regulatory compliance, kindly decline to answer.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Return concise information answering the question and citing all the relevant [article_name].\n",
    "\n",
    "You can give your final anser by stating: \n",
    "Final Answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You're an expert in sustainability reporting compliance. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "\n",
    "Start your search with content related to a given query using the [search_reference] tool.\n",
    "Each article may have [article_references] to other articles. Expand your search using the [expand_search_reference] tool.\n",
    "Continue your search until all referenced information have been used to answer the question.\n",
    "\n",
    "If the question is not related to regulatory compliance, kindly decline to answer.\n",
    "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "Return concise information answering the question and citing all the relevant [article_name].\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin! Remember to answer as an expert sustainabiliy report compliance agent..\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import StringPromptTemplate\n",
    "from typing import List, Union\n",
    "\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    input_variables=['input', 'intermediate_steps']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "\n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,\n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"],\n",
    "    allowed_tools=tool_names\n",
    ")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent,\n",
    "                                                    tools=tools,\n",
    "                                                    verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: It's important to stay up-to-date on current events and regulations related to sustainability reporting.\n",
      "Action: Search\n",
      "Action Input: \"Sustainability reporting emissions standards\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/langchain_community/utilities/duckduckgo_search.py:63: UserWarning: backend='api' is deprecated, using backend='auto'\n",
      "  ddgs_gen = ddgs.text(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mIFRS Sustainability Standards are developed to enhance investor-company dialogue so that investors receive decision-useful, globally comparable sustainability-related disclosures that meet their information needs. ... 29 jurisdictions that have finalised or published proposals on climate-related disclosures have included Scope 3 GHG emissions ... Climate-related disclosure requirements from the International Sustainability Standards Board (ISSB), the EU and the Securities and Exchange Commission (SEC) are shaping the global climate reporting landscape. Although different in many ways, these requirements share a common factor: greenhouse gas emissions. On June 26, 2023, the International Sustainability Standards Board (ISSB), an International Financial Reporting Standards (IFRS) Foundation initiative, released IFRS S1, General Requirements for Disclosure of Sustainability-related Financial Information and IFRS S2, Climate-related Disclosures; both are effective for years beginning on or after January 1, 2024, with earlier application permitted. ISO 14064 is an international standard developed by the International Organisation for Standardisation (ISO) to provide a consistent framework for measuring, reporting, and verifying GHG emissions. It is part of the broader ISO 14000 family, which focuses on environmental management standards designed to support sustainability efforts across industries. 3. GRI Standards. Developed by the Global Reporting Initiative, the GRI Standards are a modular framework that includes sets of universal, sector-specific and topic-based sustainability reporting standards. Companies can also use them to disclose the impacts their business operations have on the economy, the environment and people.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mAfter searching, it seems that there are multiple standards for reporting emissions, including IFRS Sustainability Standards, ISO 14064, and GRI Standards.\n",
      "Final Answer: The standards for reporting emissions include IFRS Sustainability Standards, ISO 14064, and GRI Standards. It is important to stay up-to-date on these standards and regulations in order to accurately report emissions and meet the information needs of investors.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are the standards for reporting emissions?',\n",
       " 'output': 'The standards for reporting emissions include IFRS Sustainability Standards, ISO 14064, and GRI Standards. It is important to stay up-to-date on these standards and regulations in order to accurately report emissions and meet the information needs of investors.'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"input\": \"What are the standards for reporting emissions?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
